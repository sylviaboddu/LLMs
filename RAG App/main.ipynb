{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os \n",
    "from langchain_community.chat_models import ChatOpenAI\n",
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_openai.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain_community.vectorstores import FAISS,DocArrayInMemorySearch\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableParallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "Model = 'gpt-3.5-turbo'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The capital of the United States is Washington, D.C.', response_metadata={'token_usage': {'completion_tokens': 12, 'prompt_tokens': 15, 'total_tokens': 27}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-737354f6-55b1-44e0-bbe9-af933c7344b2-0', usage_metadata={'input_tokens': 15, 'output_tokens': 12, 'total_tokens': 27})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ChatOpenAI(api_key=API_KEY,model=Model)\n",
    "model.invoke('what is the capita of UAS?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = StrOutputParser()\n",
    "chain = model|parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Coding is the process of using a programming language to create instructions that a computer can understand and execute. It involves writing lines of code to create software, websites, apps, or other types of digital content. Coding requires logical thinking, problem-solving skills, and attention to detail.'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke('what is coding?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_loader = PyPDFLoader('malnutrition detection.pdf')\n",
    "page = file_loader.load_and_split()\n",
    "len(page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='of Science and Technology,  \\nChennai, India.  \\nsaravanan_cse_2019@crescent.educati\\nonPavani B  \\nDepartment of Computer Science and \\nEngineering,  \\nB. S. Abdur Rahman Crescent Institute', metadata={'source': 'malnutrition detection.pdf', 'page': 0})"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spliter = RecursiveCharacterTextSplitter(chunk_size = 200,chunk_overlap = 50)\n",
    "pages = spliter.split_documents(page)\n",
    "pages[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_storage = FAISS.from_documents(pages,OpenAIEmbeddings())\n",
    "retriever = vector_storage.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_template = \"\"\"\n",
    "your a smart bot that answers questions based on the context given to you only.\n",
    "You don't make things up.\n",
    "context:{context}\n",
    "question:{question}\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "your a smart bot that answers questions based on the context given to you only.\n",
      "You don't make things up.\n",
      "context: Here is the context to use\n",
      "question: Answer this question based on the context\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = PromptTemplate.from_template(template=question_template)\n",
    "print(prompt.format(context = ' Here is the context to use',\n",
    "              question = ' Answer this question based on the context'\n",
    "              ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = RunnableParallel(context= retriever,question = RunnablePassthrough())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = result |prompt | model | parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The model classifies the input image into 3 categories.'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke('how many classes does the model classifies the input image into?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='and it is observed that the model achieved 96% of accuracy \\nfor the learning rate of 0.001 as shown in Fig 6.  The final \\nresults were classified into 3 categories based upon image', metadata={'source': 'malnutrition detection.pdf', 'page': 3}),\n",
       " Document(page_content='one million images from the ImageNet database and can \\nclassify images into 1000 object categories, such as a \\nkeyboard, mouse, pencil, and many animals. As a result, the', metadata={'source': 'malnutrition detection.pdf', 'page': 2}),\n",
       " Document(page_content='classification and all the images in the dataset resized to the \\ndimensions of 227x227x3 for training and testing process.  \\n \\nFig. 5.  Training progress of the network', metadata={'source': 'malnutrition detection.pdf', 'page': 2}),\n",
       " Document(page_content='images, and differentiates one from the other. The architecture \\nwe used here is AlexNet for the training process and Transfer \\nLearning. The system takes the image of a child as the input', metadata={'source': 'malnutrition detection.pdf', 'page': 0})]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.invoke('how many classes does the model classifies the input image into?')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
